{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22c81e4e-8bf1-4f43-b96b-5e6631595f47",
   "metadata": {},
   "source": [
    "## Exploring Hacker News Posts\n",
    "\n",
    "In this project, we will be comparing different posts in Hacker News. We are particularly interested in looking at posts that begin with either **Ask HN** or **Show HN**. \n",
    "\n",
    "Users submit **Ask HN** posts to ask the Hacker News community a specific question, such as *\"Ask HN: How to improve my personal website?\"*. Likewise, users submit **Show HN** posts to show the Hacker News community a project, product, or just something interesting, such as, *\"Show HN: Shanhu.io, a programming playground powered by e8vm\"*. \n",
    "\n",
    "We are interested to compare these two types of posts to determine the following:\n",
    "* Do Ask HN or Show HN receive more comments on average?\n",
    "* Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "It should be note that the [dataset](https://www.kaggle.com/datasets/hacker-news/hacker-news-posts) that we are using has been reduced to 20,000 rows from almost 300,000 rows, by removing all the submissions that did not receive any comments, and then randomly sampling from the remaining submissions. \n",
    "\n",
    "### Introduction \n",
    "\n",
    "We will first start off by importing our CSV file using the below codechunk:\n",
    "* importing reader from csv\n",
    "* open the 'hacker_news.csv' file using `open()` function\n",
    "* use the `reader()` function that we have imported earlier to read the`opened_file`\n",
    "* use `list()` function to list `read_file` and assigned it to the variable `hn` as list-of-list.\n",
    "* Extract the first row of data and assigning it to `headers` as the header of the csv file.\n",
    "* Extract the rest of the dataset and assign it as `hn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f597d2ad-3184-4aa6-acb3-00d6357684c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n",
      "\n",
      "\n",
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "\n",
    "print(hn[:5])\n",
    "print('\\n')\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95915ee8-60a6-4c0e-ac8b-c33c3549b18d",
   "metadata": {},
   "source": [
    "As shown above, the header row is successfully removed. \n",
    "\n",
    "Now, our data set displays each of these items separately:\n",
    "* `ID:`ID of post\n",
    "* `title:` Title of the post\n",
    "* `url:`The URL of the post\n",
    "* `num_points:`The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "* `num_comments:`Number of comments of each posts\n",
    "* `author:`the username of the person who submitted the post\n",
    "* `created_at:` The date of the post that was created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2865ec68-dbbb-463c-9a75-fe7c323354ad",
   "metadata": {},
   "source": [
    "### Extracting 'Ask HN' and 'Show HN' posts.\n",
    "\n",
    "**Methodology**\n",
    "\n",
    "* **Identify** posts that begin with either `Ask HN` or `Show HN`\n",
    "* **Filter** the data for those two types of posts into separate distinct lists.\n",
    "\n",
    "  \n",
    "We will assign the **Ask HN** posts to a list `ask_posts`, the **Show HN** posts to `show_posts` and the rest to `other_posts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4a0e2c0-e734-4cb8-8a88-5b6ebec3d59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask HN: 1744\n",
      "Show HN: 1162\n",
      "Others: 17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith ('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "\n",
    "print('Ask HN:',len(ask_posts))\n",
    "print('Show HN:',len(show_posts))\n",
    "print('Others:',len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffe6bb5-fa53-4c32-8277-fb02446e72e8",
   "metadata": {},
   "source": [
    "As shown above, the `Ask HN` has **1,744** posts, `Show HN` has **1,162** posts, while `Others` has **17,194** posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "930195b3-bfe5-4d52-a002-511f9f035ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Ask HN comments: 14.038417431192661\n",
      "Average Show HN comments: 10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_ask_comments += num_comments\n",
    "    \n",
    "avg_ask_comments = total_ask_comments/len(ask_posts)\n",
    "print('Average Ask HN comments:', avg_ask_comments)\n",
    "\n",
    "total_show_comments = 0\n",
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_show_comments += num_comments\n",
    "\n",
    "avg_show_comments = total_show_comments/len(show_posts)\n",
    "print('Average Show HN comments:', avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36313e82-5018-404e-89c5-105753a6b050",
   "metadata": {},
   "source": [
    "On average, the Ask HN Comments is more than Show HN Comments. Since Ask HN posts gather more comments in general, we will focus our remaining analysis just on Ask HN Posts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66573ae4-808e-4254-b3ea-9b813528d788",
   "metadata": {},
   "source": [
    "### Finding the Number of Ask Posts and Comments by Hour Created\n",
    "\n",
    "Next, we'll determine if ask posts created at a certain time are more likely to attract comments. We'll use the following steps to perform this analysis:\n",
    "\n",
    "* Calculate the number of ask posts created in each hour of the day, along with the number of comments received.\n",
    "* Calculate the average number of comments ask posts receive by hour created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35a3948d-a15c-4669-8cb4-548000113227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'23': 543,\n",
       " '22': 479,\n",
       " '21': 1745,\n",
       " '20': 1722,\n",
       " '19': 1188,\n",
       " '18': 1439,\n",
       " '17': 1146,\n",
       " '16': 1814,\n",
       " '15': 4477,\n",
       " '14': 1416,\n",
       " '13': 1253,\n",
       " '12': 687,\n",
       " '11': 641,\n",
       " '10': 793,\n",
       " '09': 251,\n",
       " '08': 492,\n",
       " '07': 267,\n",
       " '06': 397,\n",
       " '05': 464,\n",
       " '04': 337,\n",
       " '03': 421,\n",
       " '02': 1381,\n",
       " '01': 683,\n",
       " '00': 447}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "for row in ask_posts:\n",
    "    result_list.append([row[6],int(row[4])])\n",
    "                       #First element being `created_at` column, second element being `num_comments` column\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    comment = row[1]\n",
    "    time = dt.datetime.strptime(date, \"%m/%d/%Y %H:%M\")\n",
    "    hour = time.strftime(\"%H\")\n",
    "    if hour in counts_by_hour:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += comment\n",
    "    else:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = comment\n",
    "\n",
    "sorted_comments_by_hour = dict(sorted(comments_by_hour.items(), reverse = True))\n",
    "\n",
    "sorted_comments_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c946336e-c96a-4676-8146-01df7ea4ce19",
   "metadata": {},
   "source": [
    "The dictionary that we have created above are:\n",
    "\n",
    "* `counts_by_hour`:Calculating the Average Number of Comments for Ask HN Posts by Hour\n",
    "* `comments_by_hour`: contains the corresponding number of comments ask posts created at each hour received.\n",
    "\n",
    "\n",
    "Next, we'll use these two dictionaries to calculate the average number of comments for posts created during each hour of the day.\n",
    "\n",
    "\n",
    "### Calculating the Average Number of Comments for Ask HN Posts by Hour\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44ab5ce4-1d41-4b4a-969c-c310955e50e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['23', 7.985294117647059],\n",
       " ['22', 6.746478873239437],\n",
       " ['21', 16.009174311926607],\n",
       " ['20', 21.525],\n",
       " ['19', 10.8],\n",
       " ['18', 13.20183486238532],\n",
       " ['17', 11.46],\n",
       " ['16', 16.796296296296298],\n",
       " ['15', 38.5948275862069],\n",
       " ['14', 13.233644859813085],\n",
       " ['13', 14.741176470588234],\n",
       " ['12', 9.41095890410959],\n",
       " ['11', 11.051724137931034],\n",
       " ['10', 13.440677966101696],\n",
       " ['09', 5.5777777777777775],\n",
       " ['08', 10.25],\n",
       " ['07', 7.852941176470588],\n",
       " ['06', 9.022727272727273],\n",
       " ['05', 10.08695652173913],\n",
       " ['04', 7.170212765957447],\n",
       " ['03', 7.796296296296297],\n",
       " ['02', 23.810344827586206],\n",
       " ['01', 11.383333333333333],\n",
       " ['00', 8.127272727272727]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "for hour in comments_by_hour:\n",
    "    avg = comments_by_hour[hour]/counts_by_hour[hour]\n",
    "    avg_by_hour.append([hour, avg])\n",
    "\n",
    "sorted_avg_by_hour = sorted(avg_by_hour, reverse = True)\n",
    "\n",
    "sorted_avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c512ae-529e-46bc-8763-b90e04e58817",
   "metadata": {},
   "source": [
    "It looks like the highest average comment by hour is on `3p.m`, while the lowest average comment by hour is on `9a.m`. However, this looks a little difficult to read. I will sort the list of lists and print only the 5 highest values in the format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77c124cb-ad31-4cdd-932b-945e61e0cbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.5777777777777775, '09'],\n",
       " [14.741176470588234, '13'],\n",
       " [13.440677966101696, '10'],\n",
       " [13.233644859813085, '14'],\n",
       " [16.796296296296298, '16'],\n",
       " [7.985294117647059, '23'],\n",
       " [9.41095890410959, '12'],\n",
       " [11.46, '17'],\n",
       " [38.5948275862069, '15'],\n",
       " [16.009174311926607, '21'],\n",
       " [21.525, '20'],\n",
       " [23.810344827586206, '02'],\n",
       " [13.20183486238532, '18'],\n",
       " [7.796296296296297, '03'],\n",
       " [10.08695652173913, '05'],\n",
       " [10.8, '19'],\n",
       " [11.383333333333333, '01'],\n",
       " [6.746478873239437, '22'],\n",
       " [10.25, '08'],\n",
       " [7.170212765957447, '04'],\n",
       " [8.127272727272727, '00'],\n",
       " [9.022727272727273, '06'],\n",
       " [7.852941176470588, '07'],\n",
       " [11.051724137931034, '11']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_by_hour = [] #swapping `value` to first entry and `key` to second entry\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    key = row[0]\n",
    "    value = row[1]\n",
    "    swap_avg_by_hour.append([value,key])\n",
    "\n",
    "swap_avg_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0e19d81-0f53-48fa-b6a5-ec1559cd936b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00 : 38.59, average comments per post\n",
      "02:00 : 23.81, average comments per post\n",
      "20:00 : 21.52, average comments per post\n",
      "16:00 : 16.80, average comments per post\n",
      "21:00 : 16.01, average comments per post\n"
     ]
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "\n",
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "for row in sorted_swap[:5]:\n",
    "    hr = row[1]\n",
    "    avg = row[0]\n",
    "    time1 = dt.datetime.strptime(hr, '%H').strftime('%H:%M')\n",
    "    output = \"{t} : {a:.2f}, average comments per post\".format(t = time1, a = avg)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c7232d-f29f-4771-9e57-bba6d4364d36",
   "metadata": {},
   "source": [
    "On average, the posts that gathers most comments are created at 15:00, or `3p.m` est, with an average of 38.59 comments per post. \n",
    "\n",
    "Between the first and second for highest average comments per post hours at 15:00 and 02:00, there seems to be a surge of 62% engagement in comments.\n",
    "\n",
    "According to the [documentation](https://www.kaggle.com/datasets/hacker-news/hacker-news-posts), the timezone used is US Eastern Standard Time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff059b84-17f5-4680-af00-87410a8793af",
   "metadata": {},
   "source": [
    "## Conlcusion\n",
    "\n",
    "In this project, we have analyzed the [Hacker post]((https://www.kaggle.com/datasets/hacker-news/hacker-news-posts)) dataset, with the goal of **finding out if '*Ask HN*' post or '*Show HN*' posts gather most comments on average by the hour**. We have also collected and sorted the data, formatted and cleaned the data for analysis, and analysed the data.\n",
    "\n",
    "Based on our analysis, the highest average comments by post type would be:\n",
    "* To have the post categorised as *Ask HN* post\n",
    "* Created between 15:00 to 16:00 US Eastern Standard Time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
